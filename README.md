# AI Loan System - Full Stack Application

ğŸ¦ **An intelligent loan eligibility platform with AI chat, voice interaction, document verification, and PDF report generation.**

This project is a **free-tier version** that replicates cloud-style loan processing systems (chat, OCR, ML scoring, reporting) using **open-source alternatives** and **local services** that run entirely on your machine.

---
## DemoğŸ“·


https://github.com/user-attachments/assets/3bb50548-ca52-4b69-98fb-3b1bd8e47976



## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Tech Stack](#tech-stack)
4. [Prerequisites](#prerequisites)
5. [Installation](#installation)
6. [Running the Application](#running-the-application)
7. [API Documentation](#api-documentation)
8. [Frontend Features](#frontend-features)
9. [Testing Guide](#testing-guide)
10. [Project Structure](#project-structure)
11. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Overview

The AI Loan System automates the loan application process by:

- **Chat Interface**: Users interact with an AI agent (powered by Ollama/Llama3) to discuss loan options
- **Voice Input/Output**: Speech-to-text (Whisper) and text-to-speech (gTTS) for accessibility
- **Document Verification**: OCR-based (Tesseract) document extraction and validation
- **ML Prediction**: XGBoost model predicts loan eligibility based on applicant data
- **PDF Reports**: Jinja2 + WeasyPrint generates professional loan application reports
- **Manager Dashboard**: Review applications, make decisions, and download reports
- **JWT Authentication**: Secure user authentication with bcrypt password hashing

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    React Frontend (Port 3000)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Chatbot   â”‚  â”‚  Voice   â”‚  â”‚ Document Uploadâ”‚          â”‚
â”‚  â”‚   (AI)     â”‚  â”‚ Input/Outâ”‚  â”‚   & Verify     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        Manager Dashboard & Decision Making         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ HTTP/REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FastAPI Backend (Port 8000)                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Chat API   â”‚  â”‚  Voice API   â”‚  â”‚   OCR API    â”‚      â”‚
â”‚  â”‚  (Ollama)    â”‚  â”‚  (Whisper)   â”‚  â”‚ (Tesseract)  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Loan API    â”‚  â”‚ Report API   â”‚  â”‚ Manager API  â”‚      â”‚
â”‚  â”‚  (XGBoost)   â”‚  â”‚(WeasyPrint)  â”‚  â”‚   (Admin)    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    SQLite Database (SQLAlchemy ORM)                â”‚   â”‚
â”‚  â”‚    Users | Applications | Chat Sessions            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ollama     â”‚  â”‚    Whisper      â”‚  â”‚  Tesseract    â”‚
â”‚  (LLM Chat)  â”‚  â”‚  (STT & TTS)    â”‚  â”‚  (OCR)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Tech Stack

### Backend
- **Framework**: FastAPI (Python)
- **Database**: SQLite (default) or Postgres/Supabase via SQLAlchemy
- **Authentication**: JWT (python-jose) + bcrypt
- **LLM Chat**: Pluggable via `LLM_PROVIDER` (`ollama`, `gemini`, `openrouter`)
- **Voice (batch, local)**: Whisper CLI (STT) + FFmpeg + gTTS (TTS) over REST in `voice_routes` (`/api/voice/transcribe`, `/api/voice/synthesize`, `/api/voice/voice_agent`)
- **Voice (real-time, cloud)**: Deepgram Novaâ€‘2 streaming STT + Groq Llama 3 (`AsyncGroq`) + Deepgram Aura streaming TTS in `voice_realtime_v2` (WebSocket `/voice/stream` mounted under the voice realtime v2 API)
- **Voice (real-time, local alternative)**: Vosk STT + Piper TTS via WebSocket in `voice_realtime.py`, with environment/health checks exposed from `voice_health.py`
- **Document OCR**: Tesseract (with graceful mock fallback)
- **ML Model**: XGBoost + Scikit-learn via `MLModelService`
- **PDF Generation**: Jinja2 + WeasyPrint via `ReportService`
- **Notifications & OTP**: Email-based OTP and WebSocket manager notifications

### Frontend
- **Framework**: React 18
- **Styling**: Tailwind CSS + custom design system
- **HTTP Client**: Axios wrappers in `src/utils/api.js`
- **Routing**: React Router v6 (see `src/App.js`)
- **State/UX**: Toasts (`react-toastify`), framer-motion animations

### Local / External Services
- **Ollama**: Local LLM inference server (default provider)
- **Tesseract**: Open-source OCR engine
- **Whisper**: OpenAI's CLI speech recogniser for file-based STT in the batch voice agent
- **Vosk**: Offline streaming STT backend used by the local WebSocket agent (`voice_realtime.py`)
- **Piper**: Offline low-latency TTS used by the local WebSocket agent (`voice_realtime.py`)
- **Deepgram**: Cloud STT + TTS (Novaâ€‘2 + Aura) used by the default real-time voice agent (`voice_realtime_v2.py`)
- **Groq**: Cloud LLM (Llama 3) used by the default real-time voice agent (`voice_realtime_v2.py`)

---

## ğŸ“¦ Prerequisites

### System Requirements
- **OS**: macOS (M1/M2 preferred, or Intel)
- **Node.js**: 18.x or higher
- **Python**: 3.11 or higher
- **RAM**: 8GB+ recommended
- **Disk**: 5GB+ for models and dependencies

### Required Software

#### 1. **Ollama** (LLM Chat)
```bash
# Install Ollama from https://ollama.ai
# Or via Homebrew:
brew install ollama

# Pull llama3 model (2.7GB)
ollama pull llama3

# Run Ollama server (default port 11434)
ollama serve
```

#### 2. **Tesseract** (OCR)
```bash
# Install via Homebrew
brew install tesseract

# Verify installation
tesseract --version
```

#### 3. **Whisper** (Speech Recognition)
```bash
# Will be installed via pip (openai-whisper)
# First time usage will download model (~2.7GB for base model)
```

#### 4. **Node.js & npm**
```bash
# Check version
node --version  # Should be 18+
npm --version   # Should be 9+
```

---

## ğŸš€ Installation

### 1. Clone the Repository

```bash
cd ~/Documents/Machine_Learning_Projects/Infosys_Project
# If using git:
# git clone <repo-url>
# Or navigate to existing folder:
cd ai-loan-system
```

### 2. Backend Setup (API + default users)

```bash
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create .env file (if you don't have one yet)
cp .env.example .env  # or create backend/.env manually

# Edit .env with your settings (local defaults shown below)
```

### 3. Train ML Model (optional but recommended)

**âš ï¸ IMPORTANT**: You must provide your own trained ML model, or adapt `ml/loan_training.py` to your dataset. The repo ships a template only.

```bash
# From project root
cd ml

# Edit loan_training.py to load your own dataset
# Implement load_your_dataset() with your data source
$EDITOR loan_training.py

# Run the training script (will error until you implement loading)
python3 loan_training.py

# By default this saves a model to:
#   ml/app/models/loan_model.pkl
```

**Default template dataset requirements (if you follow `loan_training.py` as-is):**
- Tabular data with columns: `annual_income`, `credit_score`, `loan_amount`, `loan_term_months`, `num_dependents`, `employment_status`, `eligible`
- `eligible` column should be 0 (ineligible) or 1 (eligible)
- At least 1000+ samples recommended for a stable model

### 3b. Using your own pre-trained model (no training step)

If you already have trained artifacts, place them in the models directory and the backend will auto-detect them at startup.

Supported filenames and locations:

- Directory: `ml/app/models/`
- Model file (any of): `loan_model.pkl`, `loan_xgboost_model.pkl`, or `model.pkl`
- Optional pre-processing files in the same directory:
  - `scaler.pkl` or `feature_scaler.pkl` (StandardScaler)
  - `label_encoders.pkl` (dict of sklearn LabelEncoder per categorical feature)

Alternatively, you can configure a custom directory via environment variable in `backend/.env`:

```
ML_MODEL_DIR=/absolute/path/to/ai-loan-system/ml/app/models
```

`MLModelService` will look for artifacts in this order:
1) `ML_MODEL_DIR` env variable (absolute or relative to backend)
2) The parent directory of an explicitly provided model path (internal use)
3) `ml/app/models` relative to the repo root
4) Fallback to `backend/app/models`

### 4. Frontend Setup

```bash
cd ../frontend

# Install dependencies
npm install

# Create .env file
echo "REACT_APP_API_URL=http://localhost:8000/api" > .env
```

---

## â–¶ï¸ Running the Application

### Terminal 1: Start Ollama Server
```bash
ollama serve
# Output: Listening on 127.0.0.1:11434
```

### Terminal 2: Start Backend
```bash
cd backend
source venv/bin/activate
python main.py
# Or with uvicorn directly:
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Backend will be available at**: `http://localhost:8000`
**API Documentation**: `http://localhost:8000/docs` (Swagger UI)

### Terminal 3: Start Frontend
```bash
cd frontend
npm start
# Will open http://localhost:3000 in browser
```

<<<<<<< HEAD
### 4. Default Login Credentials

**Admin (Manager)**
- **Email**: `admin@example.com`
- **Password**: `admin123`

**Applicant**
- **Email**: `user@example.com`
- **Password**: `user123`

=======
>>>>>>> origin/main
## ğŸ”‘ Environment Variables

- Backend: copy `backend/.env.example` to `backend/.env` and adjust.
- Frontend: copy `frontend/.env.example` to `frontend/.env` and adjust.

Backend keys (most important):
- SECRET_KEY: JWT signing secret (set a strong value in prod).
- DATABASE_URL: DB connection string (SQLite default, Postgres optional).
- DB_SCHEMA: Postgres schema (default `public`).
- SUPABASE_HOSTADDR: Optional IP to bypass DNS for Supabase Postgres.
- LLM_PROVIDER: `ollama` | `gemini` | `openrouter`.
- OLLAMA_API_URL, OLLAMA_MODEL: Local LLM server URL and model tag.
- GEMINI_API_KEY, GEMINI_MODEL: Google Gemini key and model.
  - Get a key from Google AI Studio: https://makersuite.google.com/app/apikey
- OPENROUTER_API_KEY, OPENROUTER_MODEL, OPENROUTER_BASE_URL, OPENROUTER_SITE_URL, OPENROUTER_APP_NAME: OpenRouter config.
  - Get a key at https://openrouter.ai/ and set a default model.
- WHISPER_MODEL, WHISPER_LANGUAGE: STT model size and language hint.
- VOSK_MODEL_PATH, PIPER_MODEL: Optional local streaming STT/TTS models for the legacy Vosk+Piper WebSocket agent.
- GROQ_API_KEY, GROQ_MODEL: Groq cloud LLM settings used by the default real-time voice agent in `voice_realtime_v2.py`.
- DEEPGRAM_API_KEY: Deepgram cloud key used for both streaming STT and Aura TTS in `voice_realtime_v2.py`.
- SMTP_SERVER, SMTP_PORT, SMTP_EMAIL, SMTP_PASSWORD: Email for OTP/notifications.
- OTP_SECRET: Secret seed used for generating OTPs (dev-friendly default provided).
- ML_MODEL_DIR: Optional path to trained model artifacts.
- ACCESS_TOKEN_EXPIRE_MINUTES, ALGORITHM: JWT token config.

Example `backend/.env` (minimal local):
```env
SECRET_KEY=change-me
DATABASE_URL=sqlite:///./ai_loan_system.db
LLM_PROVIDER=ollama
OLLAMA_API_URL=http://localhost:11434/api
OLLAMA_MODEL=llama3.2
WHISPER_MODEL=tiny
WHISPER_LANGUAGE=en
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_EMAIL=your-email@gmail.com
SMTP_PASSWORD=your-app-password
```

Example `frontend/.env`:
```env
REACT_APP_API_URL=http://localhost:8000/api
```

---

## ğŸ“š API Documentation

### Authentication Endpoints

#### Register User
```

{
  "email": "user@example.com",
  "password": "securePassword123",
  "full_name": "John Doe",
}

Response: { access_token, token_type, user }
```

#### Login
```
POST /api/auth/login
{
  "email": "user@example.com",
}

```

### Chat Endpoints
POST /api/chat/message
{
  "message": "What is the loan eligibility criteria?",
  "application_id": 1  // optional
}

Response: {
  "message": "AI response text...",
  "suggested_next_steps": ["Upload document", "Check eligibility"]
}
```

### Voice Endpoints

#### Transcribe Audio
```
POST /api/voice/transcribe
Content-Type: multipart/form-data

Body: audio file (mp3, wav, m4a, etc.)

Response: { "transcribed_text": "..." }
```

#### Synthesize Speech
```
POST /api/voice/synthesize
{ "text": "Your eligibility score is 85%" }

Response: { "audio_base64": "...", "format": "mp3" }
```

### Document Verification

#### Verify Document
```
POST /api/verify/document/{application_id}
Content-Type: multipart/form-data

Body: document file (image or PDF)

Response: {
  "extracted_data": { ... },
  "confidence_scores": { ... },
  "verification_status": "success"
}
```

### Loan Prediction

#### Predict Eligibility
```
POST /api/loan/predict
{
  "annual_income": 75000,
  "credit_score": 720,
  "loan_amount": 50000,
  "loan_term_months": 60,
  "num_dependents": 2,
  "employment_status": "employed"
}

Response: {
  "eligibility_score": 0.82,
  "eligibility_status": "eligible",
  "risk_level": "low_risk",
  "recommendations": [...]
}
```

### Report Generation

#### Generate PDF Report
```
POST /api/report/generate/{application_id}

Response: {
  "report_path": "/path/to/report.pdf",
  "report_url": "/static/reports/report.pdf",
  "generated_at": "2024-01-15T10:30:00"
}
```

#### Download Report
```
GET /api/report/download/{application_id}

Response: PDF file (binary)
```

### Manager Dashboard

#### Get Statistics
```
GET /api/manager/stats

Response: {
  "total_applications": 50,
  "pending_applications": 10,
  "approved_applications": 35,
  "rejected_applications": 5
}
```

#### Get All Applications
```
GET /api/manager/applications?status_filter=pending&skip=0&limit=20

Response: [ { id, full_name, loan_amount, eligibility_score, ... }, ... ]
```

#### Make Decision
```
POST /api/manager/applications/{application_id}/decision
{
  "decision": "approved",  // or "rejected"
  "notes": "Good credit score and income ratio"
}

Response: { "success": true, "approval_status": "approved" }
```

---

## ğŸ¨ Frontend Features

### 1. **Login/Registration**
- User registration (Applicant or Manager role)
- Secure JWT-based login
- Session management

### 2. **Applicant Dashboard**
- **Chatbot**: Interact with AI loan advisor
- **Voice Input**: Record and transcribe voice questions
- **Document Upload**: Upload ID, paystubs, bank statements
- **Eligibility Check**: View loan eligibility score

### 3. **Manager Dashboard**
- **Statistics**: Total, pending, approved, rejected applications
- **Application List**: Filter by status
- **Decision Making**: Approve or reject applications
- **Report Download**: Get PDF reports for applications

---

## ğŸ§ª Testing Guide

### Test 1: User Registration & Login

```bash
# Using curl or Postman:

# Register
curl -X POST http://localhost:8000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "Test123!",
    "full_name": "Test User",
    "role": "applicant"
  }'

# Login
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "Test123!"
  }'
```

### Test 2: Chat Interaction

```bash
# Send a message
curl -X POST http://localhost:8000/api/chat/message \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What is your loan eligibility criteria?",
    "application_id": 1
  }'
```

### Test 3: Loan Eligibility Prediction

```bash
curl -X POST http://localhost:8000/api/loan/predict \
  -H "Content-Type: application/json" \
  -d '{
    "annual_income": 75000,
    "credit_score": 720,
    "loan_amount": 50000,
    "loan_term_months": 60,
    "num_dependents": 2,
    "employment_status": "employed"
  }'
```

### Test 4: Document Upload & Verification

```bash
curl -X POST http://localhost:8000/api/verify/document/1 \
  -F "file=@/path/to/document.jpg"
```

### Test 5: PDF Report Generation

```bash
curl -X POST http://localhost:8000/api/report/generate/1 \
  -H "Authorization: Bearer YOUR_TOKEN"
```

---

## ğŸ“‚ Project Structure

```
ai-loan-system/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                          # FastAPI entry point
â”‚   â”œâ”€â”€ requirements.txt                 # Python dependencies
â”‚   â”œâ”€â”€ .env.example                     # Environment variables template
â”‚   â”œâ”€â”€ ai_loan_system.db               # SQLite database (auto-created)
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ routes/
â”‚       â”‚   â”œâ”€â”€ auth_routes.py          # Authentication endpoints
â”‚       â”‚   â”œâ”€â”€ chat_routes.py          # Chat/AI endpoints
â”‚       â”‚   â”œâ”€â”€ voice_routes.py         # Voice I/O endpoints
â”‚       â”‚   â”œâ”€â”€ ocr_routes.py           # Document verification
â”‚       â”‚   â”œâ”€â”€ loan_routes.py          # Loan prediction
â”‚       â”‚   â”œâ”€â”€ report_routes.py        # PDF report generation
â”‚       â”‚   â””â”€â”€ manager_routes.py       # Manager dashboard
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â”œâ”€â”€ ollama_service.py       # Ollama LLM integration
â”‚       â”‚   â”œâ”€â”€ voice_service.py        # Whisper & gTTS
â”‚       â”‚   â”œâ”€â”€ ocr_service.py          # Tesseract OCR
â”‚       â”‚   â”œâ”€â”€ ml_model_service.py     # XGBoost predictions
â”‚       â”‚   â””â”€â”€ report_service.py       # PDF generation
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ database.py             # SQLAlchemy models
â”‚       â”‚   â”œâ”€â”€ schemas.py              # Pydantic schemas
â”‚       â”‚   â””â”€â”€ loan_model.pkl          # Trained ML model
â”‚       â”œâ”€â”€ utils/
â”‚       â”‚   â”œâ”€â”€ security.py             # JWT & password hashing
â”‚       â”‚   â””â”€â”€ logger.py               # Logging setup
â”‚       â”œâ”€â”€ templates/
â”‚       â”‚   â””â”€â”€ report_template.html    # HTML report template
â”‚       â””â”€â”€ static/
â”‚           â”œâ”€â”€ uploads/                # Uploaded documents
â”‚           â”œâ”€â”€ voices/                 # Generated audio files
â”‚           â””â”€â”€ reports/                # Generated PDF reports
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json                    # Node dependencies
â”‚   â”œâ”€â”€ .env                            # Environment variables
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.js                      # Main component
â”‚       â”œâ”€â”€ App.css
â”‚       â”œâ”€â”€ index.js
â”‚       â”œâ”€â”€ index.css
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ Chatbot.jsx             # AI chatbot component
â”‚       â”‚   â”œâ”€â”€ LoginForm.jsx           # Auth form
â”‚       â”‚   â”œâ”€â”€ DocumentVerification.jsx # Upload & verify
â”‚       â”‚   â””â”€â”€ ManagerDashboard.jsx    # Manager UI
â”‚       â”œâ”€â”€ pages/
â”‚       â”‚   â”œâ”€â”€ Home.jsx
â”‚       â”‚   â””â”€â”€ Manager.jsx
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ api.js                  # API client
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ loan_training.py                # Model training script
â”‚   â””â”€â”€ loan_applicants_dataset.csv     # Training dataset
â””â”€â”€ README.md                           # This file
```

---

## ğŸ”§ Troubleshooting

### Issue 1: Ollama Connection Error
```
Error: Cannot connect to Ollama. Make sure it's running on localhost:11434
```

**Solution:**
```bash
# Terminal 1: Start Ollama
ollama serve

# Verify it's running
curl http://localhost:11434/api/tags
```

### Issue 2: Tesseract Not Found
```
Error: Tesseract is not installed or not found in PATH
```

**Solution:**
```bash
# Install Tesseract
brew install tesseract

# Verify
tesseract --version

# If still not found, update PATH
echo 'export PATH="/usr/local/opt/tesseract/bin:$PATH"' >> ~/.zshrc
source ~/.zshrc
```

### Issue 3: Port Already in Use
```
Error: Address already in use: ('127.0.0.1', 8000)
```

**Solution:**
```bash
# Find process using port 8000
lsof -i :8000

# Kill it
kill -9 <PID>

# Or use different port
uvicorn main:app --port 8001
```

### Issue 4: React Module Not Found
```
Error: Module not found: 'axios'
```

**Solution:**
```bash
cd frontend
npm install
npm start
```

### Issue 5: Database Locked Error
```
Error: database is locked
```

**Solution:**
```bash
# Delete and recreate database
rm backend/ai_loan_system.db
# Restart backend
```

---

## ğŸ“Š Model Performance

The XGBoost model is trained on synthetic loan applicant data with the following features:

| Feature | Range | Impact |
|---------|-------|--------|
| Annual Income | $20K - $150K | 30% |
| Credit Score | 300 - 850 | 40% |
| Loan Amount | $5K - $500K | 20% |
| Loan Term | 12 - 60 months | 5% |
| Employment Status | Employed/Self/Unemployed | 30% |
| Dependents | 0 - 4 | 10% |

**Test Accuracy**: ~85%

---

## ğŸ” Security Considerations

1. **JWT Tokens**: 30-minute expiration by default (configurable)
2. **Password Hashing**: bcrypt with 12 rounds
3. **CORS**: Configured for localhost; update for production
4. **Environment Variables**: Use `.env` file for sensitive data
5. **SQL Injection**: Protected via SQLAlchemy ORM
6. **Rate Limiting**: Implement in production

---

## ğŸš€ Deployment (Production)

### Backend Deployment (Render/Railway)

1. Push code to GitHub
2. Create account on Render.com
3. Connect repository and deploy
4. Set environment variables in platform

### Frontend Deployment (Vercel/Netlify)

1. Push code to GitHub
2. Connect repository to Vercel/Netlify
3. Set `REACT_APP_API_URL` to production API URL

### Database

For production, use:
- **PostgreSQL** (AWS RDS Free Tier)
- **MongoDB Atlas** (Free tier)
- Update `DATABASE_URL` in `.env`

---

## ğŸ“ Support & Documentation

- **FastAPI Docs**: http://localhost:8000/docs
- **Ollama Docs**: https://ollama.ai
- **Whisper Docs**: https://github.com/openai/whisper
- **Tesseract Docs**: https://github.com/UB-Mannheim/tesseract/wiki

---

## ğŸ“ License

This project is open-source and available for educational purposes.

---

## âœ… Checklist for First Run

## ğŸ”Š Voice (Vosk + Piper) Setup

Vosk (offline STT) and Piper (local TTS) are used for the real-time voice assistant.

1. Install Piper into the backend virtualenv and download a voice:

```bash
cd backend
source venv/bin/activate   # if you use a venv created by setup.sh
python -m pip install piper-tts
python -m piper.download_voices en_US-amy-medium --download-dir ./piper_voices
```

2. Download a small Vosk model (setup script tries this automatically):

```bash
curl -L -o /tmp/vosk-small.zip https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
unzip -q /tmp/vosk-small.zip -d backend/models
rm /tmp/vosk-small.zip
```

3. Set environment variables (or copy `.env.example`):

```env
VOSK_MODEL_PATH=./models/vosk-model-small-en-us-0.15
PIPER_MODEL=./piper_voices/en_US-amy-medium.onnx
```

4. Start the backend and check the voice health endpoint:

```bash
python main.py
curl http://localhost:8000/api/voice/health
```


- [ ] Python 3.11+ installed
- [ ] Node.js 18+ installed
- [ ] Ollama installed and running (`ollama serve`)
- [ ] Tesseract installed (`brew install tesseract`)
- [ ] Backend virtual environment created and activated
- [ ] Backend dependencies installed (`pip install -r requirements.txt`)
- [ ] ML model trained with your own data (`python ml/loan_training.py`)
- [ ] Frontend dependencies installed (`npm install`)
- [ ] Backend running on http://localhost:8000
- [ ] Frontend running on http://localhost:3000
- [ ] Can login at frontend and interact with AI

---

**Happy Lending! ğŸ¦ğŸ’°**
